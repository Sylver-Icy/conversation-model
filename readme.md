# ğŸ§  Conversation Model â€” Modular Agentic Dialogue Engine

A plugâ€‘andâ€‘play cognitive framework for powering personalityâ€‘driven AI characters, NPCs, and agent assistants.

This system doesnâ€™t just â€œgenerate repliesâ€ â€” it **routes, reasons, remembers, and reacts** before speaking.

---

## âœ¨ Core Capabilities

### ğŸ”¹ Intent Classification
DistilBERTâ€‘based classifier determines whether a message is:
- **Chitâ€‘chat**
- **Command**
- **Outâ€‘ofâ€‘lore / realâ€‘world query**

### ğŸ”¹ Command Classification
Second classifier identifies which command was invoked (30+ supported).

### ğŸ”¹ Mood Engine
LLMâ€‘based affect extraction + numeric mood state allows characters to:
- Change tone dynamically
- Become irritated, warm, flirty, sad, etc.
- Maintain emotional continuity across conversation

### ğŸ”¹ Semantic Memory Retrieval
Embeddings + cosineâ€‘similarity selection surfaces relevant past dialogue or lore for contextual replies.

### ğŸ”¹ Persona Prompt Composer
Injects:
- friendship level
- mood state
- chat history
- retrieved memory
- lore rules

Result = short, nonâ€‘repetitive, inâ€‘character responses.

### ğŸ”¹ Loreâ€‘Aware Decline System
If the user asks realâ€‘world / factual questions, the system produces **inâ€‘character refusal replies** instead of hallucinating.

---

## ğŸš€ Architecture Overview

```
User Message
   â†“
Intent Classifier â†’ (Chitchat / Command / Decline)
   â†“
Command Classifier (if applicable)
   â†“
Mood Engine Update
   â†“
Semantic Context Retrieval
   â†“
Persona Prompt Builder
   â†“
LLM Reply Generation
   â†“
Final Inâ€‘Character Response / Routed Command
```

---

## ğŸ— Tech Stack

- **DistilBERT** for classifiers
- **FastAPI** backend
- **Embeddings + cosine similarity** for context memory
- **LLM orchestration** for mood + persona reasoning

Models are trained via custom JSONL datasets and fully reâ€‘trainable.

---

## ğŸ“¦ Training

```bash
python classifiers/train_intent.py
python classifiers/train_command.py
```

Models saved under:

```
intent_model/
command_model/
```

GPU recommended for training (Mac/CPU okay for inference).

---

## ğŸ“‚ Dataset Format

Example JSONL row:

```json
{"text": "buy 3 apples", "label": "buy"}
```

Add new rows and retrain anytime.

---

## ğŸ”¨ Example Usage

```python
from engine.msg_gen_engine import Engine

engine = Engine()
reply = await engine.respond(
    text="yo hello?",
    frndship_title="Friend",
    user_id="u123",
    user_name="Sylver",
    message_history=[]
)
print(reply)
```
> âš ï¸ NOTE: You must train the models first â€” donâ€™t expect replies without running the training scripts.

---

## ğŸ›  Status

âœ” Stable routing
âœ” Mood + memory logic
âœ” Command gating + decline handling
âœ” Personaâ€‘aligned replies

ğŸš§ Next steps:
- Argument extraction
- Inference optimisation
- Crossâ€‘persona spawning

---

## ğŸ“Œ Notes

- Models are intentionally ignored in Git.
- Built as the engine powering **Veyra**
- `requirements.txt` is not fully maintained â€” development was split across macOS and Windows, so install missing packages manually if something errors.